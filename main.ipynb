{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pandas import DataFrame\n",
    "from autoviz.AutoViz_Class import AutoViz_Class\n",
    "from sklearn.model_selection import train_test_split\n",
    "from autogluon.tabular import TabularDataset , TabularPredictor\n",
    "\n",
    "from utils.dataset import load_dataset\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset and describe it\n",
    "\n",
    "dataset_path = 'dataset/hcvdat0.csv'\n",
    "\n",
    "\n",
    "hcv_df = load_dataset(dataset_path)\n",
    "hcv_df = hcv_df[hcv_df.columns[1:]]  # remove first 'Unnamed' column\n",
    "hcv_df.head(5)\n",
    "\n",
    "print(f'Number of different categories: {hcv_df[\"Category\"].value_counts()}')\n",
    "# describe DataFrame\n",
    "hcv_df.describe()\n",
    "\n",
    "# Identify non-numeric columns and their unique values\n",
    "for column in ['Category', 'Sex']:\n",
    "    unique_values = hcv_df[column].unique()\n",
    "    print(f'Unique values in column {column}:')\n",
    "    print(unique_values)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming string values to numeric (Category, Sex) and filling nulls\n",
    "category_mapping = {\n",
    "    '0=Blood Donor': 0,\n",
    "    '1=Hepatitis': 1,\n",
    "    '2=Fibrosis': 2,\n",
    "    '3=Cirrhosis': 3,\n",
    "    '0s=suspect Blood Donor': 4\n",
    "}\n",
    "\n",
    "sex_mapping = {\n",
    "    'm': 0,\n",
    "    'f': 1\n",
    "}\n",
    "\n",
    "replacement_dict = {\n",
    "    'Category': category_mapping,\n",
    "    'Sex': sex_mapping\n",
    "}\n",
    "\n",
    "hcv_df.replace(replacement_dict, inplace=True)\n",
    "hcv_df = hcv_df.fillna(method='ffill')\n",
    "hcv_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating an AutoViz instance\n",
    "AV = AutoViz_Class()\n",
    "\n",
    "# generating data visualization automatically\n",
    "AV.AutoViz(\n",
    "    filename='',\n",
    "    sep=',',\n",
    "    depVar='',\n",
    "    dfte=hcv_df,\n",
    "    header=0,\n",
    "    verbose=0,\n",
    "    lowess=False,\n",
    "    chart_format='svg',\n",
    "    max_rows_analyzed=10000,\n",
    "    max_cols_analyzed=30\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot correlation between columns (features)\n",
    "\n",
    "sns.heatmap(hcv_df.corr(), annot = True, annot_kws={'fontsize': 8})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train and test data\n",
    "train_df, test_df = train_test_split(hcv_df, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"./model\"\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"./model\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.0\n",
      "Python Version:     3.9.12\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   Darwin Kernel Version 23.5.0: Wed May  1 20:09:52 PDT 2024; root:xnu-10063.121.3~5/RELEASE_X86_64\n",
      "CPU Count:          6\n",
      "Memory Avail:       1.93 GB / 8.00 GB (24.2%)\n",
      "Disk Space Avail:   627.14 GB / 957.10 GB (65.5%)\n",
      "===================================================\n",
      "Train Data Rows:    492\n",
      "Train Data Columns: 12\n",
      "Label Column:       Category\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == int, but few unique label-values observed).\n",
      "\t5 unique label values:  [0, 2, 4, 3, 1]\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 4 out of 5 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 10 examples that will be kept for training models: 0.9878048780487805\n",
      "Train Data Class Count: 4\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    1976.25 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.04 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 10 | ['ALB', 'ALP', 'ALT', 'AST', 'BIL', ...]\n",
      "\t\t('int', [])   :  2 | ['Age', 'Sex']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 10 | ['ALB', 'ALP', 'ALT', 'AST', 'BIL', ...]\n",
      "\t\t('int', [])       :  1 | ['Age']\n",
      "\t\t('int', ['bool']) :  1 | ['Sex']\n",
      "\t0.1s = Fit runtime\n",
      "\t12 features in original data used to generate 12 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.04 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.09s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 388, Val Rows: 98\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t0.8878\t = Validation score   (accuracy)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t0.898\t = Validation score   (accuracy)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t0.9592\t = Validation score   (accuracy)\n",
      "\t0.46s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\tWarning: Exception caused LightGBMXT to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/Users/aleksandar77np/Desktop/master-studije/SIEDSS/sinteza-eval/virtualenv/lib/python3.9/site-packages/lightgbm/lib/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: <C3EB28DD-60B6-3334-AFA2-72BBBF9DBAEF> /Users/aleksandar77np/Desktop/master-studije/SIEDSS/sinteza-eval/virtualenv/lib/python3.9/site-packages/lightgbm/lib/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file, not in dyld cache)\n",
      "Fitting model: LightGBM ...\n",
      "\tWarning: Exception caused LightGBM to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/Users/aleksandar77np/Desktop/master-studije/SIEDSS/sinteza-eval/virtualenv/lib/python3.9/site-packages/lightgbm/lib/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: <C3EB28DD-60B6-3334-AFA2-72BBBF9DBAEF> /Users/aleksandar77np/Desktop/master-studije/SIEDSS/sinteza-eval/virtualenv/lib/python3.9/site-packages/lightgbm/lib/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file, not in dyld cache)\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.9184\t = Validation score   (accuracy)\n",
      "\t0.47s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.9286\t = Validation score   (accuracy)\n",
      "\t0.47s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t0.9286\t = Validation score   (accuracy)\n",
      "\t0.78s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.9082\t = Validation score   (accuracy)\n",
      "\t0.44s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.898\t = Validation score   (accuracy)\n",
      "\t0.48s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t0.9388\t = Validation score   (accuracy)\n",
      "\t0.33s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.9592\t = Validation score   (accuracy)\n",
      "\t1.76s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\tWarning: Exception caused LightGBMLarge to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/Users/aleksandar77np/Desktop/master-studije/SIEDSS/sinteza-eval/virtualenv/lib/python3.9/site-packages/lightgbm/lib/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: <C3EB28DD-60B6-3334-AFA2-72BBBF9DBAEF> /Users/aleksandar77np/Desktop/master-studije/SIEDSS/sinteza-eval/virtualenv/lib/python3.9/site-packages/lightgbm/lib/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file, not in dyld cache)\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'NeuralNetFastAI': 0.5, 'CatBoost': 0.5}\n",
      "\t0.9694\t = Validation score   (accuracy)\n",
      "\t0.12s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 7.29s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"./model\")\n"
     ]
    }
   ],
   "source": [
    "# Create Tabular models\n",
    "\n",
    "y_label = 'Category'\n",
    "save_model_path = './model'\n",
    "\n",
    "models = TabularPredictor(label = y_label, path = save_model_path).fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.926829268292683,\n",
       " 'balanced_accuracy': 0.5562616822429909,\n",
       " 'mcc': 0.7045635371594786}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate models on test data\n",
    "test_labels = test_df['Category']\n",
    "test_data = test_df.drop(columns = ['Category'])\n",
    "\n",
    "models = TabularPredictor.load(save_model_path)\n",
    "\n",
    "predictions = models.predict(test_data)\n",
    "eval = models.evaluate_predictions(test_labels, predictions)\n",
    "\n",
    "eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: center;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NeuralNetTorch</td>\n",
       "      <td>0.943089</td>\n",
       "      <td>0.959184</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.058263</td>\n",
       "      <td>0.019080</td>\n",
       "      <td>1.762852</td>\n",
       "      <td>0.058263</td>\n",
       "      <td>0.019080</td>\n",
       "      <td>1.762852</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.943089</td>\n",
       "      <td>0.938776</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.083847</td>\n",
       "      <td>0.003132</td>\n",
       "      <td>0.326169</td>\n",
       "      <td>0.083847</td>\n",
       "      <td>0.003132</td>\n",
       "      <td>0.326169</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestEntr</td>\n",
       "      <td>0.934959</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.195502</td>\n",
       "      <td>0.035798</td>\n",
       "      <td>0.466183</td>\n",
       "      <td>0.195502</td>\n",
       "      <td>0.035798</td>\n",
       "      <td>0.466183</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestGini</td>\n",
       "      <td>0.934959</td>\n",
       "      <td>0.918367</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.452434</td>\n",
       "      <td>0.036015</td>\n",
       "      <td>0.470955</td>\n",
       "      <td>0.452434</td>\n",
       "      <td>0.036015</td>\n",
       "      <td>0.470955</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NeuralNetFastAI</td>\n",
       "      <td>0.926829</td>\n",
       "      <td>0.959184</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.008710</td>\n",
       "      <td>0.006422</td>\n",
       "      <td>0.456732</td>\n",
       "      <td>0.008710</td>\n",
       "      <td>0.006422</td>\n",
       "      <td>0.456732</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.926829</td>\n",
       "      <td>0.969388</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.022296</td>\n",
       "      <td>0.008365</td>\n",
       "      <td>1.355884</td>\n",
       "      <td>0.010902</td>\n",
       "      <td>0.000639</td>\n",
       "      <td>0.119783</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ExtraTreesEntr</td>\n",
       "      <td>0.926829</td>\n",
       "      <td>0.897959</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.071887</td>\n",
       "      <td>0.037251</td>\n",
       "      <td>0.476312</td>\n",
       "      <td>0.071887</td>\n",
       "      <td>0.037251</td>\n",
       "      <td>0.476312</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KNeighborsDist</td>\n",
       "      <td>0.918699</td>\n",
       "      <td>0.897959</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.015602</td>\n",
       "      <td>0.014381</td>\n",
       "      <td>0.004809</td>\n",
       "      <td>0.015602</td>\n",
       "      <td>0.014381</td>\n",
       "      <td>0.004809</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KNeighborsUnif</td>\n",
       "      <td>0.918699</td>\n",
       "      <td>0.887755</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.033410</td>\n",
       "      <td>0.026666</td>\n",
       "      <td>0.014505</td>\n",
       "      <td>0.033410</td>\n",
       "      <td>0.026666</td>\n",
       "      <td>0.014505</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ExtraTreesGini</td>\n",
       "      <td>0.918699</td>\n",
       "      <td>0.908163</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.070470</td>\n",
       "      <td>0.036992</td>\n",
       "      <td>0.441394</td>\n",
       "      <td>0.070470</td>\n",
       "      <td>0.036992</td>\n",
       "      <td>0.441394</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.894309</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.002684</td>\n",
       "      <td>0.001304</td>\n",
       "      <td>0.779369</td>\n",
       "      <td>0.002684</td>\n",
       "      <td>0.001304</td>\n",
       "      <td>0.779369</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          model          score_test  score_val eval_metric  pred_time_test  \\\n",
       "0        NeuralNetTorch   0.943089   0.959184    accuracy      0.058263      \n",
       "1               XGBoost   0.943089   0.938776    accuracy      0.083847      \n",
       "2      RandomForestEntr   0.934959   0.928571    accuracy      0.195502      \n",
       "3      RandomForestGini   0.934959   0.918367    accuracy      0.452434      \n",
       "4       NeuralNetFastAI   0.926829   0.959184    accuracy      0.008710      \n",
       "5   WeightedEnsemble_L2   0.926829   0.969388    accuracy      0.022296      \n",
       "6        ExtraTreesEntr   0.926829   0.897959    accuracy      0.071887      \n",
       "7        KNeighborsDist   0.918699   0.897959    accuracy      0.015602      \n",
       "8        KNeighborsUnif   0.918699   0.887755    accuracy      0.033410      \n",
       "9        ExtraTreesGini   0.918699   0.908163    accuracy      0.070470      \n",
       "10             CatBoost   0.894309   0.928571    accuracy      0.002684      \n",
       "\n",
       "    pred_time_val  fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n",
       "0     0.019080     1.762852         0.058263                 0.019080          \n",
       "1     0.003132     0.326169         0.083847                 0.003132          \n",
       "2     0.035798     0.466183         0.195502                 0.035798          \n",
       "3     0.036015     0.470955         0.452434                 0.036015          \n",
       "4     0.006422     0.456732         0.008710                 0.006422          \n",
       "5     0.008365     1.355884         0.010902                 0.000639          \n",
       "6     0.037251     0.476312         0.071887                 0.037251          \n",
       "7     0.014381     0.004809         0.015602                 0.014381          \n",
       "8     0.026666     0.014505         0.033410                 0.026666          \n",
       "9     0.036992     0.441394         0.070470                 0.036992          \n",
       "10    0.001304     0.779369         0.002684                 0.001304          \n",
       "\n",
       "    fit_time_marginal  stack_level  can_infer  fit_order  \n",
       "0       1.762852            1         True        10      \n",
       "1       0.326169            1         True         9      \n",
       "2       0.466183            1         True         5      \n",
       "3       0.470955            1         True         4      \n",
       "4       0.456732            1         True         3      \n",
       "5       0.119783            2         True        11      \n",
       "6       0.476312            1         True         8      \n",
       "7       0.004809            1         True         2      \n",
       "8       0.014505            1         True         1      \n",
       "9       0.441394            1         True         7      \n",
       "10      0.779369            1         True         6      "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show best performing models\n",
    "models.leaderboard(test_df, silent = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
